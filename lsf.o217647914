Sender: LSF System <lsfadmin@eu-g3-030>
Subject: Job 217647914: <python eval.py --dataset cambridge_loc --scene KingsCollege --landmark line --experiment line0429/ --visualize_seg> in cluster <euler> Exited

Job <python eval.py --dataset cambridge_loc --scene KingsCollege --landmark line --experiment line0429/ --visualize_seg> was submitted from host <eu-login-05> by user <yurohu> in cluster <euler> at Sat May  7 12:22:26 2022
Job was executed on host(s) <16*eu-g3-030>, in queue <gpu.24h>, as user <yurohu> in cluster <euler> at Sat May  7 12:23:08 2022
</cluster/home/yurohu> was used as the home directory.
</cluster/home/yurohu/LVSNet/LVS-Net> was used as the working directory.
Started at Sat May  7 12:23:08 2022
Terminated at Sat May  7 12:23:37 2022
Results reported at Sat May  7 12:23:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python eval.py --dataset cambridge_loc --scene KingsCollege --landmark line --experiment line0429/ --visualize_seg
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   6.04 sec.
    Max Memory :                                 2686 MB
    Average Memory :                             1830.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13698.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   28 sec.
    Turnaround time :                            71 sec.

The output (if any) follows:

Traceback (most recent call last):
  File "eval.py", line 366, in <module>
    main()
  File "eval.py", line 357, in main
    trainer = Trainer(cfg)
  File "eval.py", line 123, in __init__
    checkpoint = torch.load(cfg["resume_checkpoint"])
  File "/cluster/home/yurohu/anaconda3/envs/vsnet/lib/python3.7/site-packages/torch/serialization.py", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/cluster/home/yurohu/anaconda3/envs/vsnet/lib/python3.7/site-packages/torch/serialization.py", line 709, in _legacy_load
    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)
KeyboardInterrupt
Params:
----------------------------------------------------
	message_prefix                :loc
	message                       :
	seed                          :1
	backbone                      :resnet
	out_stride                    :16
	sync_bn                       :False
	val_label_filter_threshsold   :20
	seg_decoder                   :v1
	seg_loss_type                 :embedding_v3
	seg_loss_margin               :0.5
	seg_k                         :2
	visualize_segmentation        :True
	vertex_decoder                :v2
	vertex_loss_type              :l1_loss
	vertex_loss_root              :1
	vertex_channel                :2
	vertex_loss_ratio             :3.0
	seg_loss_ratio                :1.0
	visualize_voting              :False
	visualize_landmark            :False
	train                         :True
	start_epoch                   :0
	eval_interval                 :5
	eval_epoch_begin              :80
	no_val                        :False
	use_pnp                       :False
	save_model                    :True
	val_batch_size                :1
	test_batch_size               :1
	shuffle                       :True
	num_workers                   :4
	base_dir                      :/cluster/project/infk/courses/252-0579-00L/group05/datasets/cambridge_line_old
	data_dir                      :
	color_map_filename            :id2colors.json
	optimizer                     :Adam
	weight_decay                  :0.0005
	momentum                      :0.9
	nesterov                      :False
	lr_scheduler                  :poly
	lr_step                       :20
	devices                       :0
	use_own_nn                    :True
	validation_debug              :False
	critical_params               :['dataset', 'scene', 'train_batch_size', 'epochs', 'lr', 'use_aug', 'seg_channel']
	resume                        :True
	resume_checkpoint             :
	checkname                     :landmarknet-resnet
	export_dir                    :logs
	log_tb_dir                    :logs
	experiment                    :line0429/
	checkpoint_dir                :ckpts
	best_model_name               :best_model.pth.tar
	write_json                    :True
	log_file                      :log.txt
	save_dir                      :/cluster/project/infk/courses/252-0579-00L/group05/models
	coding_book_filename          :channel(64)_isomap(k24)_cambridge_ShopFacade.json
	landmark                      :line
----------------------------------------------------
Critical Params:
	seg_channel                   :64
	epochs                        :100
	train_batch_size              :2
	use_aug                       :True
	dataset                       :cambridge
	scene                         :KingsCollege
	lr                            :0.0001
----------------------------------------------------
write opt to: /cluster/project/infk/courses/252-0579-00L/group05/models/cambridge_logs/line0429/dataset[cambridge]scene[KingsCollege]train_batch_size[2]epochs[100]lr[0.0001]use_aug[True]seg_channel[64]/config.json
logging to /cluster/project/infk/courses/252-0579-00L/group05/models/cambridge_logs/line0429/dataset[cambridge]scene[KingsCollege]train_batch_size[2]epochs[100]lr[0.0001]use_aug[True]seg_channel[64]/log.txt
Number of images in train: 1220
Number of images in test: 343
coding book size = torch.Size([500, 64])
Using poly LR Scheduler!
True
