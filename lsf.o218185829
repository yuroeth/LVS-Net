Sender: LSF System <lsfadmin@eu-g3-018>
Subject: Job 218185829: <python eval.py --experiment line0508/> in cluster <euler> Exited

Job <python eval.py --experiment line0508/> was submitted from host <eu-login-11> by user <yurohu> in cluster <euler> at Wed May 11 10:30:39 2022
Job was executed on host(s) <16*eu-g3-018>, in queue <gpu.24h>, as user <yurohu> in cluster <euler> at Wed May 11 14:45:44 2022
</cluster/home/yurohu> was used as the home directory.
</cluster/home/yurohu/LVSNet/LVS-Net> was used as the working directory.
Started at Wed May 11 14:45:44 2022
Terminated at Wed May 11 14:46:34 2022
Results reported at Wed May 11 14:46:34 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python eval.py --experiment line0508/
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30.73 sec.
    Max Memory :                                 16000 MB
    Average Memory :                             10495.00 MB
    Total Requested Memory :                     72000.00 MB
    Delta Memory :                               56000.00 MB
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                534
    Run time :                                   50 sec.
    Turnaround time :                            15355 sec.

The output (if any) follows:

:   0%|          | 0/343 [00:00<?, ?it/s]Test loss: 4.180853844:   0%|          | 0/343 [00:02<?, ?it/s]Test loss: 4.180853844:   0%|          | 1/343 [00:06<38:46,  6.80s/it]Test loss: 4.238081932:   0%|          | 1/343 [00:06<38:46,  6.80s/it]Test loss: 4.238081932:   1%|          | 2/343 [00:11<34:38,  6.10s/it]Test loss: 4.388053258:   1%|          | 2/343 [00:11<34:38,  6.10s/it]Test loss: 4.388053258:   1%|          | 3/343 [00:15<31:56,  5.64s/it]Test loss: 4.282164931:   1%|          | 3/343 [00:15<31:56,  5.64s/it]Test loss: 4.282164931:   1%|          | 3/343 [00:21<41:02,  7.24s/it]
Traceback (most recent call last):
  File "eval.py", line 408, in <module>
    main()
  File "eval.py", line 402, in main
    trainer.validation(trainer.cfg["start_epoch"])
  File "eval.py", line 222, in validation
    min_mask_num=self.cfg["val_label_filter_threshsold"])
  File "/cluster/home/yurohu/LVSNet/LVS-Net/utils/utils.py", line 414, in evaluate_afm
    rects = region_grow(xx, yy, theta, np.array([h, w], dtype=np.int32))
  File "/cluster/home/yurohu/anaconda3/envs/vsnet/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 9475) is killed by signal: Killed. 
Params:
----------------------------------------------------
	message_prefix                :loc
	message                       :
	seed                          :1
	backbone                      :resnet
	out_stride                    :16
	sync_bn                       :False
	val_label_filter_threshsold   :20
	seg_decoder                   :v1
	seg_loss_type                 :embedding_v3
	seg_loss_margin               :0.5
	seg_k                         :2
	visualize_segmentation        :False
	vertex_decoder                :v2
	vertex_loss_type              :l1_loss
	vertex_loss_root              :1
	vertex_channel                :2
	vertex_loss_ratio             :3.0
	seg_loss_ratio                :1.0
	visualize_voting              :False
	visualize_landmark            :False
	train                         :True
	start_epoch                   :0
	eval_interval                 :5
	eval_epoch_begin              :80
	no_val                        :False
	use_pnp                       :False
	save_model                    :True
	val_batch_size                :1
	test_batch_size               :1
	shuffle                       :True
	num_workers                   :4
	base_dir                      :/cluster/project/infk/courses/252-0579-00L/group05/datasets/cambridge_line
	data_dir                      :
	color_map_filename            :id2colors.json
	optimizer                     :Adam
	weight_decay                  :0.0005
	momentum                      :0.9
	nesterov                      :False
	lr_scheduler                  :poly
	lr_step                       :20
	devices                       :0
	use_own_nn                    :True
	validation_debug              :False
	critical_params               :['dataset', 'scene', 'train_batch_size', 'epochs', 'lr', 'use_aug', 'seg_channel']
	resume                        :True
	resume_checkpoint             :
	checkname                     :landmarknet-resnet
	export_dir                    :logs
	log_tb_dir                    :logs
	experiment                    :line0508/
	checkpoint_dir                :ckpts
	best_model_name               :best_model.pth.tar
	write_json                    :True
	log_file                      :log.txt
	save_dir                      :/cluster/project/infk/courses/252-0579-00L/group05/models
	coding_book_filename          :channel(64)_isomap(k24)_cambridge_ShopFacade.json
	landmark                      :line
----------------------------------------------------
Critical Params:
	seg_channel                   :64
	epochs                        :100
	train_batch_size              :2
	use_aug                       :True
	dataset                       :cambridge
	scene                         :KingsCollege
	lr                            :0.0001
----------------------------------------------------
write opt to: /cluster/project/infk/courses/252-0579-00L/group05/models/cambridge_logs/line0508/dataset[cambridge]scene[KingsCollege]train_batch_size[2]epochs[100]lr[0.0001]use_aug[True]seg_channel[64]/config.json
logging to /cluster/project/infk/courses/252-0579-00L/group05/models/cambridge_logs/line0508/dataset[cambridge]scene[KingsCollege]train_batch_size[2]epochs[100]lr[0.0001]use_aug[True]seg_channel[64]/log.txt
Number of images in train: 1220
Number of images in test: 343
coding book size = torch.Size([518, 64])
Using poly LR Scheduler!
True
=> loaded checkpoint True (epoch 100)
Starting Epoch: 99
Total Epoches: 100
=================================
validation
=================================
validating image: 1
detected 247 / 298 lines
90.7458788069126 2.1205447466869916 0
validating image: 2
detected 251 / 302 lines
93.45776530357097 0.9012111210193512 1
validating image: 3
detected 257 / 307 lines
59.944698409762886 1.0846261199788072 2
validating image: 4
